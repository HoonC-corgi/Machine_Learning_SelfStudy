{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNHdiW5WNKto+LDYG3FA23t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HoonC-corgi/Machine_Learning_SelfStudy/blob/main/01~06_Keyword_Summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 1"
      ],
      "metadata": {
        "id": "nYDEoMjMjbRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 인공지능 Articicial Intelligence\n",
        "      학습하고 추론할 수 있는 지능을 가진 컴퓨터 시스템을 만드는 기술"
      ],
      "metadata": {
        "id": "UZSCZHe4jgOC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 강인공지능 vs 약인공지능\n",
        "      강인공지능 = 인공일반지능, 사람의 지능과 유사\n",
        "      약인공지능은 특정 분야에서 사람을 돕는 보조 AI적 성격을 띰"
      ],
      "metadata": {
        "id": "Lj8Y4h1ljw4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Colab과 Notebook\n",
        "      코랩은 웹 브라우저에서 텍스트와 프로그램 코드를 자유롭게 작성할 수 있는 온라인 에디터로, \n",
        "      이를 코랩 노트북 or 노트북이라 부름, 최소 단위는 셀, 코드셀과 텍스트 셀이 있음"
      ],
      "metadata": {
        "id": "SL19tXbhj7yi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이진 분류 Binary Classification\n",
        "      머신러닝에서 여러 개의 종류(혹은 클래스) 중 하나를 구별해 내는 문제를 '분류'라고 하며, 양자 택일의 문제를 이진 분류라고 함"
      ],
      "metadata": {
        "id": "T6q7BNJAkLi7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 특성 feature\n",
        "      데이터를 표현하는 특징"
      ],
      "metadata": {
        "id": "q8SgPYgvke3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 맷플롯립 Matplotlib\n",
        "      파이썬에서 과학계산용 그래프를 그리는 대표적 패키지"
      ],
      "metadata": {
        "id": "eKIenm4gklfn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-최근접 이웃 알고리즘 K-Nearest Neighbors Algorithm, KNN\n",
        "      가장 간단한 머신러닝 알고리즘 중 하나로, 규칙보다는 인접한 샘플을 기반(샘플과의 직선 거리를 계산, default: 5)으로 예측을 수행함"
      ],
      "metadata": {
        "id": "JoLiBaVdkr5Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 훈련 training\n",
        "      머신러닝 알고리즘이 데이터에서 규칙을 찾는 과정\n",
        "      모델에 데이터를 전달하여 규칙을 학습하는 과정"
      ],
      "metadata": {
        "id": "ecjRNd4NlpyR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 2"
      ],
      "metadata": {
        "id": "FcieCKZ3lxP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 지도 학습 Supervise Learning\n",
        "      지도 학습은 input과 target으로 이루어진 훈련 데이터가 필요하며 새로운 데이터를 예측하는 데 활용\n",
        "      ex) K-최근접 이웃"
      ],
      "metadata": {
        "id": "f-cjhcCPmBbj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 비지도 학습 Unsupervised Learning\n",
        "      타깃 데이터 없이 input 데이터만 있을 때 사용\n",
        "      정답을 사용하지 않으므로 무언가를 맞힐 수 없지만, 데이터 파악과 변형에 도움이 됨"
      ],
      "metadata": {
        "id": "GDMC76MqmPuA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 훈련 데이터 training data\n",
        "      지도 학습의 경우 필요한 input과 target을 합쳐 놓은 것"
      ],
      "metadata": {
        "id": "CE35nbhzmaXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 훈련 세트와 테스트 세트 train set & test set\n",
        "      모델을 훈련할 때는 훈련 세트를, 평가는 테스트 세트를 사용\n",
        "      테스트 세트는 전체 데이터에서 20~30%를 사용"
      ],
      "metadata": {
        "id": "3fsxo1McmhlG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 샘플링 편향 Sampling Bias\n",
        "      훈련 세트와 테스트 샘플이 고르게 섞여 있지 않을 때 나타나며, 올바른 모델을 만들 수 없음"
      ],
      "metadata": {
        "id": "QVLgZZ-Vmu_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 넘파이 Numpy\n",
        "      파이썬의 대표적 배열 라이브러리\n",
        "      고차원의 배열을 손쉽게 만들고 조작할 수 있는 도구를 제공\n",
        "      공식 명칭 NumPy"
      ],
      "metadata": {
        "id": "9-rTWa5xm3bF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 배열 인덱싱 Array Indexing\n",
        "       넘파이 기능으로, 여러 개의 인덱스로 한 번에 여러 개의 원소를 선택 가능"
      ],
      "metadata": {
        "id": "tm0uzUz4m_nL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 전처리 Data Preprocessing\n",
        "      머신러닝 모델에 훈련 데이터를 주입하기 전 가공하는 단계, 특성값을 일정한 기준으로 맞추는 작업\n",
        "      데이터를 표현하는 기준이 다르면 알고리즘을 올바르게 예측할 수 없음"
      ],
      "metadata": {
        "id": "cv0-DThKnFl9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 브로드캐스팅 Broadcasting\n",
        "      조건을 만족하면 모양이 다른 배열 간의 연산을 가능하게 해 주는 기능"
      ],
      "metadata": {
        "id": "AoSiaOLBnPph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 3"
      ],
      "metadata": {
        "id": "opFVYoY9nV2o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 회귀 Regression\n",
        "      클래스 중 하나로 분류하는 것이 아닌, 임의의 숫자를 예측하는 문제"
      ],
      "metadata": {
        "id": "Z9nTn3h-nXWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## k-최근접 이웃 분류 vs k-최근접 이웃 회귀\n",
        "      k-최근접 이웃 알고리즘을 사용해 각각 분류와 회귀 문제를 해결하는 방법\n",
        "      분류의 경우 샘플과 직선거리 상 가까운 것을 기준으로,\n",
        "      회귀는 각 샘플의 평균값을 통해 중간 위치를 계산함"
      ],
      "metadata": {
        "id": "Xzv_lX_Pncy_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 결정계수(R^2) Coefficient of Determination\n",
        "      회귀 모델에서 예측의 적합도를 0과 1 사이의 값으로 계산한 것으로 1에 가까울 수록 완벽함\n",
        "      R^2 = 1-( (타깃-예측)^2 / (타깃-평균)^2 )"
      ],
      "metadata": {
        "id": "w_KmZDinnwj1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 과대적합 vs 과소적합 Overfitting vs Underfitting\n",
        "      과대적합은 모델의 훈련 세트 점수가 테스트 세트 점수보다 훨씬 높은 경우를 의미\n",
        "      과소적합은 모델의 훈련 세트와 테스트 세트 점수가 모두 동일하게 낮거나 테스트 세트 성능이 더 높은 경우를 의미"
      ],
      "metadata": {
        "id": "EIu9zqX7oQRU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 선형 회귀 Linear Regression\n",
        "      널리 사용되는 대표적 회귀 알고리즘\n",
        "      특성이 하나인 경우 어떠한 직선을 학습하는 알고리즘\n",
        "      가중치(계수)의 개념이 사용됨"
      ],
      "metadata": {
        "id": "mevygpQtoeB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 가중치 Weight(Coefficient)\n",
        "      선형 회귀가 학습한 직선의 기울기를가중치 or 계수라고 함"
      ],
      "metadata": {
        "id": "SpptUIhPonIk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 다항 회귀 Polynomial Regression\n",
        "      다항식을 사용하여 특성과 타깃 사이의 관계를 나타낸 선형 회귀"
      ],
      "metadata": {
        "id": "yBvzA39oo0dw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 다중 회귀 Multiple Regression\n",
        "      여러 개의 특성을 사용한 선형 회귀"
      ],
      "metadata": {
        "id": "kvr5mkS1pCmT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 변환기 Transformer\n",
        "      특성을 만들거나 전처리하는 사이킷런의 클래스로, 타깃 데이터 없이 입력 데이터를 변환함"
      ],
      "metadata": {
        "id": "8yCu5QmgpKMf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 릿지 회귀 Ridge Regression\n",
        "      규제가 있는 선형 회귀 모델 중 하나로, 모델 객체를 만들 때\n",
        "      alpha 매개변수로 규제의 강도를 조절\n",
        "      alpha 값이 크면 규제 강도가 세지므로 계수 값을 더 줄이고 과소적합 되도록 유도하여 과대적합을 완화함"
      ],
      "metadata": {
        "id": "WZqK2aukpQIQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 하이퍼파라미터 Hyperparameter\n",
        "      머신러닝 모델이 학습할 수 없고 사람이 지정하는 파라미터"
      ],
      "metadata": {
        "id": "3VYYIVJApbtU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 라쏘 회귀 Lasso Regression\n",
        "      릿지와는 다른 규제가 있는 선형 회귀 모델로,\n",
        "      alpha 매개변수로 규제의 강도를 조절\n",
        "      릿지와 달리 계수 값을 0으로 만들 수도 있음"
      ],
      "metadata": {
        "id": "qmDs9XRbpgPG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 4"
      ],
      "metadata": {
        "id": "2U5TO3Txpzim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 다중 분류 Multi-class Classification\n",
        "      타깃 데이터에 2개 이상의 클래스가 포함된 문제"
      ],
      "metadata": {
        "id": "tLHrBgUMp76S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 로지스틱 회귀 Logistic Regression\n",
        "      선형 방정식을 사용한 분류 알고리즘으로 선형 회귀와 달ㄹ ㅣ시그모이드 함수나 소프트맥스 함수를 사용하여 클래스 확률을 출력"
      ],
      "metadata": {
        "id": "kVtpQucIqLMJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 로지스틱 함수(시그모이드 함수) Logistic Regression(Sigmoid Function)\n",
        "      시그모이드 함수 또는 로지스틱 함수라고 부르며,\n",
        "      선형 방정식의 출력을 0과 1사이의 값으로 압축하며 이진 분류를 위해 사용함\n",
        "      이진 분류의 경우 시그모이드 함수의 출력이 0.5보다 크면 양성 클래스, 작으면 음성 클래스로 판단"
      ],
      "metadata": {
        "id": "yDoyR3ctqUjj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 불리언 인덱싱 Boolean Indexing\n",
        "      넘파이 배열은 True, False 값을 전달하여 행을 선택할 수 있음"
      ],
      "metadata": {
        "id": "fnN4QCJRqsfl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 소프트맥스 함수 softmax function\n",
        "      여러 개의 선형 방정식의 출력값을 0~1 사이로 압축하고 전체 합이 1이 되도록 만들며,\n",
        "      이를 위해 지수 함수를 사용하기에 정규화된 지수 함수라고도 함"
      ],
      "metadata": {
        "id": "73KD7h4Iq-lM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 확률적 경사 하강법 Stochastic Gradient Descent\n",
        "      훈련 세트에서 랜덤하게 하나의 샘플을 선택하여 손실함수의 경사를 다라 최적의 모델을 찾는 알고리즘\n",
        "      경사를 조금씩 내려가는 것이 정확성을 높임"
      ],
      "metadata": {
        "id": "0u5RNk1KrRDd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 에포크 Epoch\n",
        "      확률적 경사 하강법에서 훈련 세트를 한 번 모두 사용하는 과정"
      ],
      "metadata": {
        "id": "dVB-dhVsrenl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 미니배치 경사 하강법 Minibatch Gradient Descent\n",
        "      1개가 아닌 여러 개의 샘플을 사용해 경사 하강법을 수행하는 방법, 실전에 많이 사용됨"
      ],
      "metadata": {
        "id": "BQWle7uurita"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 배치 경사 하강법 Batch Gradient Descent\n",
        "      한 번에 전체 샘플을 사용하는 방법으로, 전체 데이터를 사용하므로 가장 안정적이지만 컴퓨터 자원 소모가 큼\n",
        "      데이터가 너무 많은 경우 한 번에 데이터 전량을 처리할 수 없을 수도 있음"
      ],
      "metadata": {
        "id": "XTv4pu72rq3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 손실 함수 Loss Function\n",
        "      어떤 문제에서 머신러닝 알고리즘이 얼마나 엉터리인지를 측정하는 기준"
      ],
      "metadata": {
        "id": "mG-ec83Pr2I0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 로지스틱 손실 함수(이진 크로스엔트로피 손실 함수) Logistic Loss Function\n",
        "      양성 클래스(타깃=1)일 때 손실은 -log(예측 확률)로 계산하며, 이 확률이 1에서 멀어질수록 손실은 큰 양수가 됨.\n",
        "      음성 클래스 (타깃=0)일 때 손실은 -log(1-예측 확률)로 계산하며, 이 예측 확률이 0에서 멀어질 수록 손실은 큰 양수가 됨"
      ],
      "metadata": {
        "id": "VmjiWajer87D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 크로스엔트로피 손실 함수 Cross-entropy Loss Function\n",
        "      다중 분류에서 사용하는 손실 함수"
      ],
      "metadata": {
        "id": "e6PrbwrEsY52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 힌지 손실 Hinge Loss\n",
        "      서포트 벡터 머신 Support Vector Machine이라 불리는 또 다른 머신러닝 알고리즘을 위한 손실 함수로, 널리 사용되는 머신러닝 알고리즘 중 하나임.\n",
        "      SGDClassifier가 여러 종류의 손실 함수를 loss 매개변수에 지정하여 다양한 머신러닝 알고리즘을 지원"
      ],
      "metadata": {
        "id": "NWTYqfTCsijJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 5"
      ],
      "metadata": {
        "id": "Ad8zV29ls1G2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 결정 트리 Decision Tree\n",
        "      스무고개와 같이 질문을 하나씩 던져 정답을 맞춰가며 학습하는 알고리즘, 직관적"
      ],
      "metadata": {
        "id": "0KznQPJ9s4eV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 검증 세트 Validation Set\n",
        "      하이퍼파라미터 튜닝을 위해 모델을 평가할 때, 테스트 세트를 사용하지 않기 위해 훈련세트에서 다시 떼어 낸 세트\n",
        "      훈련 세트 : 검증 세트 : 테스트 세트 = 6 : 2 : 2"
      ],
      "metadata": {
        "id": "UTNqt_BQtBEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 교차 검증 Cross Validation\n",
        "      훈련 세트를 여러 폴드로 나눈 다음 한 폴드가 검증 세트의 역할을 하고 나머지 폴드에서는 모델을 훈련\n",
        "      모든 폴드에 대해 검증 점수를 얻어 평균하는 방법으로,\n",
        "      교차 검증을 이용하면 검증점수가 안정적이며, 훈련에 더 많은 데이터를 사용할 수 있음"
      ],
      "metadata": {
        "id": "WbsHQ90CtP7K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 그리드 서치 Grid Search\n",
        "      하이퍼파라미터 탐색을 자동화해 주는 도구"
      ],
      "metadata": {
        "id": "5D9YTYMJthF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 랜덤 서치 Random Search\n",
        "      랜덤 서치는 연속적인 매개변수 값을 탐색할 때 유용"
      ],
      "metadata": {
        "id": "6SDibU6Jtm7U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 정형 데이터 vs 비정형 데이터 Structured Data vs Unstructured Data\n",
        "      특정 구조로 이루어진 데이터를 정형 데이터라 하고, 반면 정형화되기 어려운 사진이나 음악 등을 비정형 데이터라 함"
      ],
      "metadata": {
        "id": "iKPbSMRCttJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 앙상블 학습 Ensemble Learning\n",
        "      여러 알고리즘(ex, 결정트리)을 합쳐서 성능을 높이는 머신러닝 기법"
      ],
      "metadata": {
        "id": "9V-vecHyt3Oj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 랜덤 포레스트 Random Forest\n",
        "      대표적인 결정 트리 기반의 앙상블 학습 방법, 안정적인 성능 덕분에 널리 사용됨\n",
        "      **부트스트랩 샘플을 사용하고 랜덤하게 일부 특성을 선택**하여 트리를 만드는 것이 특징"
      ],
      "metadata": {
        "id": "d2wqkIC2t-pD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 부트스트랩 샘플 Bootstrap Sample\n",
        "      데이터 세트에서 중복을 허용하여 데이터를 샘플링하는 방식"
      ],
      "metadata": {
        "id": "E2-4v2s8uMLb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 엑스트라 트리 Extra Trees\n",
        "      랜덤 포레스트와 비슷하게 동작하며 결정 트리를 사용하여 앙상블 모델을 만듦.\n",
        "      **부트스트랩 샘플을 사용하지 않는 대신 랜덤하게 노드를 분할**하여 과대적합을 감소시킴."
      ],
      "metadata": {
        "id": "uCdIGXp3uR-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 그레이디언트 부스팅 Gradient Boosting\n",
        "      깊이가 얕은 결정 트리를 사용하여 이전트리의 오차를 보완하는 방식으로 앙상블 하는 방법, 깊이가 얕은 결정 트리를 사용하기에 **과대적합에 강하고 일반적으로 높은 일반화 성능**을 기대할 수 있음"
      ],
      "metadata": {
        "id": "p-AihS3gukvW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 히스토그램 기반 그레이디언트 부스팅 Histogram-based Gradient Boosting\n",
        "      그레이디언트 부스팅의 속도를 개선한 것으로,\n",
        "      과대적합에 강하며 그레이디언트 부스팅보다 조금 더 높은 성능을 제공\n",
        "      **안정적인 결과와 높은 성능**으로 인기가 높음"
      ],
      "metadata": {
        "id": "98Jev7XnvCQh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 6"
      ],
      "metadata": {
        "id": "wV9K6C7IvT2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 히스토그램 Histogram\n",
        "      값이 발생한 빈도를 그래프로 표시한 것으로 보통 x축이 값의구간(계급)이고, y축은 발생 빈도(도수)임"
      ],
      "metadata": {
        "id": "QAxakmfSvVka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 군집 Clustering\n",
        "      **비슷한 샘플끼리 그룹으로 모으는 작업**으로, 대표적인 비지도 학습 작업 중 하나"
      ],
      "metadata": {
        "id": "W2C3PHCbvcch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## k-평균 알고리즘 K-Means Algorithm\n",
        "      처음에 랜덤하게 클러스터 중심을 정하여 클러스터를 만들고,\n",
        "      클러스터의 중심을 이동하여 다시 클러스터를 결정하는 식을 반복하여 최적의 클러스터를 구성하는 알고리즘\n",
        "      엘보우를 통해 지정"
      ],
      "metadata": {
        "id": "0vosef5RvjTd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이너셔 Inertia\n",
        "      k-평균 알고리즘은 클러스터 중심과 클러스터에 속한 샘플 사이의 거리를 잴 수 있음\n",
        "      이 거리의 제곱 합을 이너셔라고 함\n",
        "      **클러스터의 샘플이 얼마나 가깝게 있는지를 나타내는 값**"
      ],
      "metadata": {
        "id": "6sUtn23Mv69E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 차원 축소 Dimensionality Reduction\n",
        "      데이터를 가장 잘 나타내는 일부 특성을 선택하여 데이터 크기를 줄이고 지도 학습 모델의 성능을 향상시킬 수 있는 방법"
      ],
      "metadata": {
        "id": "FtJSCXTLwJI1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 주성분 분석 Principal Component Analysis, PCA\n",
        "      차원 축소 알고리즘의 하나로** 주성분(데이터에서 가장 분산이 큰 방향)**을 찾는 방법으로,\n",
        "      원본 데이터를 주성분에 투영하여 새로운 특성을 만들 수 있음."
      ],
      "metadata": {
        "id": "daTPS_vvwUU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iOU1pzjqws3O"
      }
    }
  ]
}