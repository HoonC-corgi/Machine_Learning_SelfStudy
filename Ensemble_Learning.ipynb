{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfcZAo3K8pqAqzKrusb2TW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HoonC-corgi/Machine_Learning_SelfStudy/blob/main/Ensemble_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Algorythm"
      ],
      "metadata": {
        "id": "d4luNMibzXVy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Classifier"
      ],
      "metadata": {
        "id": "1XaGmRK40Q8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "wine = pd.read_csv('http://bit.ly/wine_csv_data')\n",
        "data = wine[['alcohol', 'sugar', 'pH']].to_numpy()\n",
        "target = wine['class'].to_numpy()\n",
        "train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "gnFOrgjRzaJl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cross_validate() 메소드를 통한 교차검증 수행\n",
        "# return_train_score 매개변수를 True로 지정함으로써 훈련 세트에 대한 점수도 동시에 반환\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
        "scores = cross_validate(rf, train_input, train_target,\n",
        "                        return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A3OKmVN0v0Q",
        "outputId": "834f9a8a-4567-4459-e278-49d9fda7b3c0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9973541965122431 0.8905151032797809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤 포레스트는 결정 트리의 앙상블이기에 특성 중요도를 계산할수 있다\n",
        "rf.fit(train_input, train_target)\n",
        "print(rf.feature_importances_)\n",
        "# 랜덤 포레스트는 특정 특성에 과도하게 집중하지 않고 다양한 특성이 훈련에 기여할 기회를 얻기에 과대적합의 완화와 일반화 성능을 높임"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm-V0gHk1Lnz",
        "outputId": "387fb2b7-7160-462b-b224-3f480cf1103a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.23167441 0.50039841 0.26792718]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤 포레스트 분류는 자체적으로 모델 평가 점수를 얻을 수 있음.\n",
        "# 부트스트랩 샘플에 포함되지 않고 남게 되는 OOB샘플을 통해 훈련된 결정트리를 평가\n",
        "# oob_score 매개변수를 True로 지정하고 OOB 점수의 평균을 구함\n",
        "rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n",
        "rf.fit(train_input, train_target)\n",
        "print(rf.oob_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5YLTHgO18Wi",
        "outputId": "17ecee41-eec1-4e6a-87e6-bd144bf216a8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8934000384837406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 엑스트라 트리\n",
        "      엑스트라 트리는 부트스트랩 샘플을 사용하지 않고, 무작위로 샘플링함 결정트리의 splitter='random'과 같음"
      ],
      "metadata": {
        "id": "l6ipVYTe24A-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n",
        "scores = cross_validate(et, train_input, train_target,\n",
        "                        return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n",
        "# 일반적으로 엑스트라 트리가 무작위성이 크기에 더 많은 결정트리를 훈련해야 하지만, 랜덤하게 노드를 분할하기에 계산 속도가 빠르다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6GhoQgA20Xb",
        "outputId": "f3aa7284-6d16-448e-8990-6bf1a3bfa304"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9974503966084433 0.8887848893166506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "et.fit(train_input, train_target)\n",
        "print(et.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pd8uXXxo3rv8",
        "outputId": "ab2b50ca-a8ce-4316-caf7-e8f104b17b33"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.20183568 0.52242907 0.27573525]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Boosting\n",
        "      얕은 깊이의 결정트리를 사용하여 이전트리의 오차를 보완하는 앙상블 방식"
      ],
      "metadata": {
        "id": "HJvegPcu4N_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "scores = cross_validate(gb, train_input, train_target,\n",
        "                        return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n",
        "# 그레이디언트 부스팅은 결정 트리의 개수를 늘려도 과대적합에 강함"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lJYMjVT4Imj",
        "outputId": "3f0af154-f912-49d5-cc66-fa0af20e49c1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8881086892152563 0.8720430147331015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습률과 결정트리의 개수를 증가시킴으로 성능을 향상시킬 수 있음\n",
        "gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2, random_state=42)\n",
        "scores = cross_validate(gb, train_input, train_target,\n",
        "                        return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-wrFCpW44Dt",
        "outputId": "25755176-3a4a-48c2-8211-70681d62b1d6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9464595437171814 0.8780082549788999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gb.fit(train_input, train_target)\n",
        "print(gb.feature_importances_)\n",
        "# 그레이디언트 부스팅은 랜덤 포레스트보다 일부 특성에 더 집중함"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy7ivQrJ6Gi-",
        "outputId": "879eec89-98a0-4bd2-8e7f-47c6afcc4017"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.15872278 0.68010884 0.16116839]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Histogrm-based Gradient Boosting\n",
        "       입력 특성을 256개의 구간으로 우선적으로 나누고 노드를 분할 하므로 최적의 분할을 빠르게 찾을 수 있음, 누락된 특성을 전처리할 필요 없음\n",
        "       max_iter 매개변수를 통해 성능을 향상 시킬 수 있음"
      ],
      "metadata": {
        "id": "mswZX8qF6dA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "hgb = HistGradientBoostingClassifier(random_state=42)\n",
        "scores = cross_validate(hgb, train_input, train_target,\n",
        "                        return_train_score=True)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HulJYy9m6QhS",
        "outputId": "d0bec686-1ef7-4055-ef91-dc03483921ed"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9321723946453317 0.8801241948619236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 히스토그램 기반 그레이디언트 부스팅의 특성 중요도 계산을 위해서는 permutation_importance() 메소드를 사용함, 특성을 하나씩 랜덤 셔플하여 모델 성능의 변화를 관찰하여 중요도를 계산\n",
        "# n_repeats 매개변수는 랜덤 셔플 횟수를 지정\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "hgb.fit(train_input, train_target)\n",
        "result = permutation_importance(hgb, train_input, train_target,\n",
        "                                n_repeats=10, random_state=42, n_jobs=-1)\n",
        "print(result.importances_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3zhpLzB7Oui",
        "outputId": "07de6571-d421-4324-a0d1-5f940128ba7d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.08876275 0.23438522 0.08027708]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 히스토그램 기반 그레이디언트 부스팅 분류의 최종 성능을 구하면\n",
        "hgb.score(test_input, test_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QELiTWR076nG",
        "outputId": "aaba7dc8-5e5a-4b68-9de6-3d35a3c97b59"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8723076923076923"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost를 이용한 그레이디언트 부스팅 구현"
      ],
      "metadata": {
        "id": "UPHCRX_k8-yL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 그레이디언트 부스팅 알고리즘을 지원하는 대표 라이브러리 XGBoost를 통해 이를 구현\n",
        "# tree_method 매개변수를 'hist'로 지정\n",
        "from xgboost import XGBClassifier\n",
        "xgb = XGBClassifier(tree_method='hist', random_state=42)\n",
        "scores = cross_validate(xgb, train_input, train_target,\n",
        "                        return_train_score=True)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOHZQduf8Dsk",
        "outputId": "7c5ccfd0-c21f-4f0f-9ad3-5a838d0482d0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8824322471423747 0.8726214185237284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGBM을 이용한 그레이디언트 부스팅 구현"
      ],
      "metadata": {
        "id": "AaF3Tvme9Gl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "lgb = LGBMClassifier(random_state=42)\n",
        "scores = cross_validate(lgb, train_input, train_target,\n",
        "                        return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIcJI2ZP8t4X",
        "outputId": "ca05c930-6076-45bd-fae6-12a5f8bf69f2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9338079582727165 0.8789710890649293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전체 소스코드"
      ],
      "metadata": {
        "id": "mJP_RDxT-VJn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp6fW8MP-mrO"
      },
      "source": [
        "# 트리의 앙상블"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv1IwHmU-mrU"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/hg-mldl/blob/master/5-3.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩에서 실행하기</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIaIAizcRSG-"
      },
      "source": [
        "## 랜덤포레스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioJUlZ0M_uSZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "wine = pd.read_csv('https://bit.ly/wine_csv_data')\n",
        "\n",
        "data = wine[['alcohol', 'sugar', 'pH']].to_numpy()\n",
        "target = wine['class'].to_numpy()\n",
        "\n",
        "train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDKQudr7_8nu",
        "outputId": "91033069-881d-4b8e-fe74-3f257adee340"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9973541965122431 0.8905151032797809\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
        "scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYDbzXNLG8fK",
        "outputId": "cb099fcb-d0e4-47d6-afcc-50603903b072"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.23167441 0.50039841 0.26792718]\n"
          ]
        }
      ],
      "source": [
        "rf.fit(train_input, train_target)\n",
        "print(rf.feature_importances_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMc06S1Fa_A-",
        "outputId": "6ffc1c75-f649-46ab-d982-8bbb1cb094f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8934000384837406\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n",
        "\n",
        "rf.fit(train_input, train_target)\n",
        "print(rf.oob_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdrVoeQZRU14"
      },
      "source": [
        "## 엑스트라트리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noMLdywdOGrE",
        "outputId": "821d4676-0cfc-4622-c3eb-f451f27f88e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9974503966084433 0.8887848893166506\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n",
        "scores = cross_validate(et, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnB0_mBqfcXL",
        "outputId": "a95a7542-4aae-4e52-dddf-0f0560505631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.20183568 0.52242907 0.27573525]\n"
          ]
        }
      ],
      "source": [
        "et.fit(train_input, train_target)\n",
        "print(et.feature_importances_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csKxnaxeRX8s"
      },
      "source": [
        "## 그레이디언트 부스팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IlNEFkaNsoG",
        "outputId": "95fa643b-e8e4-4e93-effe-c5e7c5413960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8881086892152563 0.8720430147331015\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNpeS8EWpeEi",
        "outputId": "0bb5e9f8-7744-4a66-99a9-4efe78d26408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9464595437171814 0.8780082549788999\n"
          ]
        }
      ],
      "source": [
        "gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2, random_state=42)\n",
        "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD6iWVsGqCAE",
        "outputId": "6bd3a2dc-ac93-46dc-e5ce-233844355e42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.15872278 0.68010884 0.16116839]\n"
          ]
        }
      ],
      "source": [
        "gb.fit(train_input, train_target)\n",
        "print(gb.feature_importances_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BthW_II9RbLa"
      },
      "source": [
        "## 히스토그램 기반 부스팅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3Ct_NNWQbdA",
        "outputId": "eb153285-251c-480e-a27a-9b334fa83394"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9321723946453317 0.8801241948619236\n"
          ]
        }
      ],
      "source": [
        "# 사이킷런 1.0 버전 아래에서는 다음 라인의 주석을 해제하고 실행하세요.\n",
        "# from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "hgb = HistGradientBoostingClassifier(random_state=42)\n",
        "scores = cross_validate(hgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvlB0GMTS3hn",
        "outputId": "0ae9b5d3-3067-47f6-be58-a6dbed4efe0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.08876275 0.23438522 0.08027708]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "hgb.fit(train_input, train_target)\n",
        "result = permutation_importance(hgb, train_input, train_target, n_repeats=10,\n",
        "                                random_state=42, n_jobs=-1)\n",
        "print(result.importances_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8FfxInn-xBQ",
        "outputId": "23805528-ee9b-4469-d172-0d263948361b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.05969231 0.20238462 0.049     ]\n"
          ]
        }
      ],
      "source": [
        "result = permutation_importance(hgb, test_input, test_target, n_repeats=10,\n",
        "                                random_state=42, n_jobs=-1)\n",
        "print(result.importances_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqplZjh0j2nw",
        "outputId": "f4fa41ce-782f-40ce-f5fc-279f76b6c34b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8723076923076923"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hgb.score(test_input, test_target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fz_FrezBezR"
      },
      "source": [
        "#### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBYLvOiV6rga",
        "outputId": "eac4a826-83bd-4ebe-944c-6e8b9e9e4575"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9555033709953124 0.8799326275264677\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb = XGBClassifier(tree_method='hist', random_state=42)\n",
        "scores = cross_validate(xgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl6nh6DOBd-B"
      },
      "source": [
        "#### LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maihlDMP7lmY",
        "outputId": "ba7429ca-1eac-4b7b-fac7-fcf766f2fd10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.935828414851749 0.8801251203079884\n"
          ]
        }
      ],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "lgb = LGBMClassifier(random_state=42)\n",
        "scores = cross_validate(lgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 총정리\n",
        "  ## 키워드\n",
        "  ### 앙상블 학습\n",
        "          정형 데이터를 훈련하여 각 모델의 예측을 취합하여 최종 결과를 만드는 학습 방식\n",
        "\n",
        "  ### 랜덤 포레스트\n",
        "          대표적인 결정 트리 기반의 앙상블 학습 방법, 부트스트랩 샘플을 사용하고 랜덤하게 일부 특성을 선택하여 트리를 만듦\n",
        "\n",
        "  ### 엑스트라 트리\n",
        "          랜덤포레스트와 비슷하지만 부트스트랩 샘플을 사용하지 않고 랜덤하게 노드를 분할해 과대적합을 감소시킴\n",
        "\n",
        "  ### 그레이디언트 부스팅\n",
        "          랜덤 포레스트, 엑스트라 트리와 다르게 결정 트리를 연속적으로 추가하여 손실 함수를 최소화 하는 앙상블 방법, 훈련 속도가 느리고 높은 성능을 보임\n",
        "          이를 개선한 히스토그램 기반 그레이디언트 부스팅이 안정적이고 높은 성능을 보임\n",
        "\n",
        "\n",
        "  ## 핵심 패키지와 함수\n",
        "  ## scikit-learn\n",
        "  ### RandomForestClassifier\n",
        "          n_estimators 매개변수를 통해 트리의 개수를 지정, 디폴트는 100\n",
        "          criterion 매개변수를 통해 불순도를 지정, 디폴트는 지니 불순도 'gini'와 엔트로피 불순도 'entropy'가 있음\n",
        "          max_depth를 통해 트리의 최대 성장 깊이를 지정, 디폴트는 None으로 리프 노드가 순수하거나 min_samples_split보다 샘플 개수가 적을 때까지 성장\n",
        "          min_samples_split은 노드를 나누기 위한 최소 샘플 개수, 디폴트는 2\n",
        "          max_features 매개변수는 최적의 분할을 위해 탐색할 특성의 개수를 지정, 디폴트는 auto로 특성 개수의 제곱근\n",
        "          bootstrap 매개변수는 부트스트랩 샘플을 사용할지 지정, 디폴트는 True\n",
        "          oob_score는 OOB 샘플을 사용하여 훈련한 모델을 평가할지 지정, 디폴트는 False\n",
        "          n_jobs를 통해 병렬 실행에 사용할 CPU 코어수를 지정, 디폴트는 -1으로 보든 코어를 사용\n",
        "\n",
        "  ### ExtraTreesClassifier\n",
        "          bootstrap 매개변수를 통해 부트스트랩 샘플의 사용여부를 지정, 디폴트는 False\n",
        "          oob_score는 OOB 샘플을 사용하여 훈련한 모델을 평가할지 지정, 디폴트는 False\n",
        "          n_jobs를 통해 병렬 실행에 사용할 CPU 코어수를 지정, 디폴트는 -1으로 보든 코어를 사용\n",
        "\n",
        "  ### GradientBoostingClassifier\n",
        "        loss 매개변수는 손실함수를 지정, 디폴트는 로지스틱 손실 함수인 'deviance'\n",
        "        learning_rate 매개변수는 트리가 앙상블에 기여하는 정도를 조절, 디폴트는 0.1\n",
        "        n_estimators 매개변수를 통해 부스팅 단계를 수행하는 트리의 개수를 지정, 디폴트는 100\n",
        "        subsample 매개변수를 통해 사용할 훈련 세트의 샘플 비율을 지정, 디폴트는 1.0\n",
        "        max_depth 매개변수를 통해 개별 회귀 트리의 최대 깊이를 지정, 디폴트는 3\n",
        "\n",
        "  ### HistGradientBoostingClassifier\n",
        "        learning_rate 매개변수는 학습률 또는 감쇠율이라 함, 디폴트는 0.1이며 1.0이면 감쇠가 전혀 없음\n",
        "        max_iter는 부스팅 단계를 수행하는 트리의 개수, 디폴트는 100\n",
        "        max_bins는 입력 데이터를 나눌 구간의 개수로, 디폴트는 255이며 이보다 클 수 없음\n",
        "\n",
        "\n",
        "  # 앙상블 학습 정리\n",
        "      앙상블 학습은 정형 데이터에서 가장 뛰어난 성능을 내는 머신러닝 알고리즘\n",
        "\n",
        "  ## 사이킷런\n",
        "\n",
        "  ### 랜덤 포레스트\n",
        "        부트스트랩 샘플 사용, 대표 앙상블 학습 알고리즘\n",
        "  ### 엑스트라 트리\n",
        "        결정 트리의 노드를 랜덤하게 분할\n",
        "  ### 그레이디언트 부스팅\n",
        "        이전 트리의 손실을 보완하는 식으로 얕은 결정트리를 연속하여 추가\n",
        "  ### 히스토그램 기반 그레이디언트 부스팅\n",
        "        훈련 데이터를 256개의 정수 구간으로 나누어 빠르고 높은 성능을 냄, 255개를 디폴트로 사용, 나머지 하나는 누락된 클래스를 위해 사용 됨\n",
        "\n",
        "\n",
        "  ## 그외 라이브러리\n",
        "  ### XGBoost\n",
        "  ### LightGBM"
      ],
      "metadata": {
        "id": "cpW6ELhj-ah5"
      }
    }
  ]
}